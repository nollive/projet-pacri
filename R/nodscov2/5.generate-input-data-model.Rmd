---
title: 'loc-to-RData'
author: 'Olivier GAUFRÃˆS'
date: '2024-07-12'
output: html_document
---

## Librairies 
```{r}
# Librairies
library(data.table)
library(tidyverse)
library(Rcpp)
rm(list=ls())

# Paths
sensitivity_path <- file.path('..','..', "out", 'sensitivity-analysis')
scenarios_path <- file.path('..','..', "out", 'scenarios-analysis')

# Load data 
loc_path <- file.path('..','..', "out",'loc-nodscov2','dev-localization-nodscov2.RData')
load(loc_path)
```

## Modification of the global objects
```{r}
# Create admission_sim dataframe 
admission_sim = admission %>%
  mutate(info = ifelse(status == 'PE', 1, 0)) %>%
  select(id,info) %>%
  left_join(., rooms, by = 'id') %>%
  mutate(room = ifelse(info == 1, as.integer(rooms[rooms$id == 'M-PM', 'id_room']), as.integer(room)),
         info = as.integer(info)) %>%
  select(id,info,room)

# Create global status dataframe that will be used to store the epidemic dynamics
global_status = data.frame(
  id = admission$id, 
  t_inf = as.integer(-1), 
  t_incub = as.integer(-1), 
  t_recover = as.integer(-1), 
  inf_by = '', 
  inf_room = as.integer(-1)
  )

# Create global_environment list to store aerosol quantities at each time step
env_t = rooms %>%
  group_by(room, id_room) %>%
  summarise(volume = max(volume), .groups = "drop") %>%
  mutate(env = 0, id_room = as.integer(id_room)) %>%
  select(room, id_room, env, volume)

global_environment <- lapply(1:n_subdivisions, function(t){
  return (env_t)
})
rm(env_t)

```


## Truncation of the interaction objects
## This chunk has to be removed after implementing the synthetic network algorithm
```{r}
# Truncate interaction data to keep only 24h (24/05/06 12:00 TO 24/05/07 12:00)
end_date - begin_date ##end of last interaction
new_begin_date <- begin_date + (5*60*60) ## OFFSET TO START THE DAY AT 12AM
new_end_date <- new_begin_date + (24*60*60)
print(new_end_date - new_begin_date)
t_begin <- 5*60*2 ## OFFSET t
t_end <- (t_begin + 24*60*2) - 1

## TRUNCATED INFO EXTRACTED FROM TOTAL STUDY (KEEP 24HOURS OF THE 36HOURS)
truncated_interaction <- global_interaction[(u <- seq_along(global_interaction)) %in% t_begin:(t_end)]
truncated_interaction <- map(truncated_interaction, select, c(from,to,localization)) ##remove useless variables
truncated_localization <- global_localization[(u <- seq_along(global_localization)) %in% t_begin:(t_end)]
truncated_environment <- global_environment[(u <- seq_along(global_environment)) %in% t_begin:(t_end)]

## FILTER INDIVIDUALS NOT INTERACTING
id_interacting <- do.call(rbind,truncated_interaction) %>%
  pivot_longer(cols = c(from, to), names_to = 'direction', values_to = 'individual') %>%
  distinct(individual) %>%
  pull()

## FILTER THE DFS TO REMOVE USELESS ROWS (INDIVIDUALS NOT INTERACTING)
filter_interacting <- function(list_df, id_interacting) {
  lapply(list_df, function(df) {
    df %>% 
      filter(id %in% id_interacting)
  })
}

truncated_localization <- filter_interacting(truncated_localization, id_interacting )
truncated_status <- global_status %>% filter(id %in% id_interacting)
admission <- admission %>% filter(id %in% id_interacting)
admission_sim <- admission_sim  %>% filter(id %in% id_interacting)

truncated_data <- lapply(1:length(truncated_localization), function(t){
  df <- data.frame(id = truncated_localization[[t]]$id,
                   info = admission_sim$info,
                   #room = admission_sim$room,
                   #interacting = ifelse(id %in% truncated_interaction$from | id %in% truncated_interaction$to, T, F)
                   localization_ti = truncated_localization[[t]]$localization,
                   lambda_c = 0,
                   lambda_e = 0
  )
  df <- df %>% filter(localization_ti != -1)
  return(df)
})
```

## Create endless day
## This chunk has to be removed after implementing the synthetic network algorithm
```{r}
#########################
## ENDLESS DAY OBJECTS ##
#########################
n_days <- 90
new_n_subdivisions <- (t_end - t_begin + 1) * n_days

global_interaction <- rep(truncated_interaction, n_days)
global_environment <- rep(truncated_environment, n_days)
global_data <- rep(truncated_data, n_days)
global_status <- truncated_status
```


## Simulate new patients
## This chunk has to be removed after implementing the synthetic network algorithm
```{r}
###############################
## ADMISSIONS AND DISCHARGES ##
###############################
df_data_long <- rbindlist(global_data, idcol='time')
df_data_long$time <- df_data_long$time + (t_begin - 1) ##OFFSET

df_interaction_long <- rbindlist(global_interaction, idcol='time')
df_interaction_long$time <- df_interaction_long$time + (t_begin - 1) ##OFFSET


id_patient <- admission_sim %>% 
  filter(info == 0) %>%
  pull(id)
base_id <- substr(tail(admission_sim$id, 1), 1, 4)

# increment IDs
increment_id <- function(last_id, base_id) {
  last_number <- substr(last_id, 5, 8)
  new_number <- sprintf("%04d", as.numeric(last_number) + 1)
  paste0(base_id, new_number, '-N-P')
}

## ADD NEW PATIENTS
for (patient in id_patient){
  i <- t_begin ##OFFSET DUE TO TRUNCATED DATA
  iter <- 0
  info_patient <- admission_sim %>% filter(id == patient)
  status_patient <- data.frame(id = NA, t_inf = -1, t_incub = -1, t_recover = -1, inf_by = NA, inf_room = -1)
  
  while (i < new_n_subdivisions & iter < 25) {
    i_sampled <- as.integer(runif(1, min = 6*24*60*2, max = 13*24*60*2)) ## MEAN TIME ICU W/O AND W/ COVID-19
    
    last_id <- tail(admission_sim$id, 1)
    new_id <- increment_id(last_id, base_id)
    df_data_long[id == patient & between(time, i, i + i_sampled - 1), id := new_id]
    df_interaction_long[from == patient & between(time, i, i + i_sampled - 1), from := new_id]
    df_interaction_long[to == patient & between(time, i, i + i_sampled - 1), to := new_id]
    iter <- iter + 1
    i <- i + i_sampled
    ## ADD THE NEW PATIENT
    status_patient$id <- new_id
    info_patient$id <- new_id
    admission_sim <- rbind(admission_sim,  info_patient)
    global_status <- rbind(global_status, status_patient )
  }
}

# DATAFRAME TO LIST OF DATAFRAME 
global_data <- split(df_data_long, df_data_long$time)
global_interaction <- split(df_interaction_long, df_interaction_long$time)
rm(df_data_long, df_interaction_long)
```

## List of model parameters
```{r}
# Fixed parameters 
B <- 0.48 * 24 # Breathing rate (0.48 m3/h)
mu_air <- 1 # Natural ventilation, Quanta removal (1 changes/day)
mu_ventilation <-  4 * 24 # Mechanical ventilation, Quanta removal (4-6 Air changes/h)
mu_inac <- (log(2)/1.1) * 24 # Quanta inactivation (computed with viral half life -> 0.63 quanta inactivated/h) 
mu <- mu_air + mu_inac #+ (mu_ventilation - mu_air)
dt <- 30 # Time step
tau <- 60 * 60 *24 # Seconds in 1 day
deltat <- dt/tau
env_model = "linear"
nu <- 12 * 24 # (12 quanta/h)

# Parameters explored in the simulation study (tested to give the same 20% SAR)
beta_c <- 3/2 * 24 # Transmission rate for close contact interaction /h
beta_e <- 20
```

## Save the final object used as input of the epidemic simulation algorithm 
```{r}
# Pay attention: it might take a while to save the 
# the global objects when the number of days is high
save_path <- file.path(scenarios_path, "parameters-admission-nodscov2.RData")

save(global_interaction,
     global_data,
     global_status,
     global_environment,
     admission_sim,
     admission,
     beta_c,
     beta_e,
     nu,
     mu,
     B,
     env_model,
     dt,
     new_n_subdivisions,
     n_days,
     t_begin,
     t_end,
     new_begin_date,
     new_end_date,
     file = save_path
     )
```

